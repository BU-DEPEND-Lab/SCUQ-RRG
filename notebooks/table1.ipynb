{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RaDialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/restricted/projectnb/batmanlab/chyuwang/RaDialog/exp/text_score/green_scores-3858.pkl', 'rb') as file:\n",
    "    green_score = pickle.load(file)\n",
    "# Load data\n",
    "us = np.array([t.numpy() for t in green_score['greens']])\n",
    "pe = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp/uncertainty/u_nll.csv')\n",
    "u_nll = np.array(pe['u_nll'].values)\n",
    "\n",
    "pe = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp/uncertainty/u_normnll.csv')\n",
    "u_normnll = np.array(pe['u_normnll'].values)\n",
    "\n",
    "with open('/restricted/projectnb/batmanlab/chyuwang/RaDialog/exp/uncertainty/green_uncertainty-3858.pkl', 'rb') as file:\n",
    "    green_uncertainty = pickle.load(file)\n",
    "ugreen = np.array([t.numpy() for t in green_uncertainty['uncertainty']])\n",
    "\n",
    "u_lexicalsim = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/RaDialog/UQ/lexicalUQ.csv')\n",
    "u_lexicalsim = u_lexicalsim['ROUGE_L_UQ'].values\n",
    "u_lexicalsim = [1-i for i in u_lexicalsim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/RaDialog/scores/report_scores_-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green-based uncertainty\n",
    "tmp = [[hd,pearsonr(u_lexicalsim[:-1],res[hd])[0]] for hd in res.keys()[4:]]\n",
    "tmp.append(['Green',pearsonr(u_lexicalsim,np.array([t.numpy() for t in green_score['greens']]))[0]])\n",
    "# tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bleu_score', -0.12424457632311656],\n",
       " ['bertscore', -0.3813386608867214],\n",
       " ['semb_score', -0.2680022574546058],\n",
       " ['radgraph_combined', -0.24946701628655962],\n",
       " ['radgraph_recall', -0.16670518743220006],\n",
       " ['radgraph_precision', -0.3145536245393259],\n",
       " ['RadCliQ-v0', 0.37208062142865717],\n",
       " ['RadCliQ-v1', 0.3561650453294739],\n",
       " ['Green', -0.3874721623952201]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CheXpertPlus_mimiccxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "score = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/ChexpertPlus/green_scores-chexpert-plus-3858.csv',header=None)\n",
    "ugreen = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/ChexpertPlus/chexpert-plus-green_uncertainty-3858.csv',header=None)\n",
    "score = np.array([float(t.replace(\"tensor(\", \"\").replace(\")\", \"\")) for t in score[0].values])\n",
    "ugreen = np.array([float(t.replace(\"tensor(\", \"\").replace(\")\", \"\")) for t in ugreen[0].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['greedy_reports', 'sampled_reports'])\n"
     ]
    }
   ],
   "source": [
    "with open('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp/chexpert-plus/batch_chexpert_mimix_cxr_num3858.pkl', 'rb') as file:\n",
    "    chexpert_plus = pickle.load(file)\n",
    "print(chexpert_plus.keys())\n",
    "all_sample_list = [list(item) for item in chexpert_plus['sampled_reports']]\n",
    "all_pred_list = chexpert_plus['greedy_reports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_format(pred, path):\n",
    "    df = pd.DataFrame(pred, columns=['report'])\n",
    "    df['study_id'] = list(range(0, len(pred)))\n",
    "    df.to_csv(path)\n",
    "path = '/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/ChexpertPlus/cxr_benchmark/cxr_benchmark_pred.csv'\n",
    "benchmark_format(all_pred_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark score\n",
    "res = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/ChexpertPlus/cxr_benchmark/chexpertPlus_report_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bleu_score', -0.09393861555630342],\n",
       " ['bertscore', -0.3400121045840589],\n",
       " ['semb_score', -0.297176916761688],\n",
       " ['radgraph_combined', -0.2762155933827057],\n",
       " ['radgraph_recall', -0.2270117815353259],\n",
       " ['radgraph_precision', -0.3020472463043725],\n",
       " ['RadCliQ-v0', 0.37434614450493314],\n",
       " ['RadCliQ-v1', 0.3551033730131634],\n",
       " ['Green', -0.4726145635334426]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Green-based uncertainty\n",
    "tmp = [[hd,pearsonr(ugreen,res[hd])[0]] for hd in res.keys()[5:]]\n",
    "tmp.append(['Green',pearsonr(ugreen,score)[0]])\n",
    "tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bleu_score', -0.15166650617857919],\n",
       " ['bertscore', -0.31482739286045713],\n",
       " ['semb_score', -0.25245472150232484],\n",
       " ['radgraph_combined', -0.2637871055101423],\n",
       " ['radgraph_recall', -0.23295228832573978],\n",
       " ['radgraph_precision', -0.2732435763224098],\n",
       " ['RadCliQ-v0', 0.3294635977536766],\n",
       " ['RadCliQ-v1', 0.32108790101103146],\n",
       " ['Green', -0.3491043008752382]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LexicalSim uncertainty\n",
    "u_lexicalsim = pd.read_csv('/restricted/projectnb/batmanlab/chyuwang/rrg_factual_uncertainty/exp_result/ChexpertPlus/chexpert-plus_lexicalUQ.csv')\n",
    "u_lexicalsim = u_lexicalsim['ROUGE_L_UQ'].values\n",
    "tmp = [[hd,pearsonr(-u_lexicalsim,res[hd])[0]] for hd in res.keys()[5:]]\n",
    "tmp.append(['Green',pearsonr(-u_lexicalsim,score)[0]])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
